---
title: "Data Analysis"
subtitle: "Comprehensive Data Cleaning & Exploratory Data Analysis of Job Market Trends"
author:
  - name: Connor Coulter
    affiliations:
      - id: bu
        name: Boston University
        city: Boston
        state: MA
  - name: Wei Wang
    affiliations:
      - ref: bu
  - name: Balqis Bevi Abdul Hannan Kanaga
    affiliations:
      - ref: bu
bibliography: references.bib
csl: csl/econometrica.csl
format: 
  html:
    embed-resources: true
    toc: true
    number-sections: true
    df-print: paged
execute:
  echo: false      # hide code in HTML
  eval: true
  freeze: false    # always rebuild
jupyter: python3
---

# Import Data

```{python}
import pandas as pd

csv_path = "data/lightcast_job_postings.csv"   # ensure the CSV is here
df = pd.read_csv(csv_path, low_memory=False)

print("Loaded dataset:", df.shape)
display(df.head(5))
```

# Data Cleaning & Preprocessing

## Dropping Unnecessary Columns
```{python}
columns_to_drop = [
    "ID","LAST_UPDATED_TIMESTAMP","DUPLICATES","ACTIVE_URLS","ACTIVE_SOURCES_INFO",
    "TITLE_RAW","BODY","COMPANY_RAW",
    "NAICS2","NAICS2_NAME","NAICS3","NAICS3_NAME","NAICS4","NAICS4_NAME",
    "NAICS5","NAICS5_NAME","NAICS6","NAICS6_NAME",
    "NAICS_2022_2","NAICS_2022_2_NAME","NAICS_2022_3","NAICS_2022_3_NAME",
    "NAICS_2022_4","NAICS_2022_4_NAME","NAICS_2022_5","NAICS_2022_5_NAME",
    "SOC_2","SOC_2_NAME","SOC_3","SOC_3_NAME","SOC_5","SOC_5_NAME",
    "CIP2","CIP2_NAME","CIP4","CIP4_NAME","CIP6","CIP6_NAME",
    "LOT_CAREER_AREA","LOT_CAREER_AREA_NAME","LOT_OCCUPATION","LOT_OCCUPATION_NAME",
    "LOT_SPECIALIZED_OCCUPATION","LOT_SPECIALIZED_OCCUPATION_NAME",
    "LOT_OCCUPATION_GROUP","LOT_OCCUPATION_GROUP_NAME",
    "LOT_V6_SPECIALIZED_OCCUPATION","LOT_V6_SPECIALIZED_OCCUPATION_NAME",
    "LOT_V6_OCCUPATION","LOT_V6_OCCUPATION_NAME","LOT_V6_OCCUPATION_GROUP",
    "LOT_V6_OCCUPATION_GROUP_NAME","LOT_V6_CAREER_AREA","LOT_V6_CAREER_AREA_NAME",
    "ONET","ONET_NAME","ONET_2019","ONET_2019_NAME"
]
existing = [c for c in columns_to_drop if c in df.columns]
# no inplace
df = df.drop(columns=existing, errors="ignore")
print("Remaining columns (first 30):", list(df.columns)[:30])
```

## Handling Missing Values
```{python}
# Optional missingness heatmap (won't crash if libs not installed)
try:
    import missingno as msno, matplotlib.pyplot as plt
    msno.heatmap(df)
    plt.title("Missing Values Heatmap")
    plt.show()
except Exception as e:
    print("missingno heatmap skipped:", e)

# Drop columns with >50% missing (no inplace)
df = df.dropna(thresh=len(df) * 0.5, axis=1)

# Numeric salary: convert & median-fill (no inplace)
if "SALARY" in df.columns:
    df["SALARY"] = pd.to_numeric(df["SALARY"], errors="coerce")
    df["SALARY"] = df["SALARY"].fillna(df["SALARY"].median())

# Fill categorical NAs with "Unknown" (no chained assignment)
for col in df.select_dtypes(include="object").columns:
    df.loc[:, col] = df[col].fillna("Unknown")
```

## Removing Duplicates
```{python}
subset_cols = [c for c in ["TITLE","COMPANY_NAME","LOCATION","POSTED"] if c in df.columns]
if subset_cols:
    before = len(df)
    df = df.drop_duplicates(subset=subset_cols, keep="first")
    print(f"Removed {before - len(df)} duplicates using {subset_cols}")
else:
    print("No standard duplicate keys found; skipping.")
```

# Exploratory Data Analysis (EDA)

```{python}
# Robust column pickers
INDUSTRY_CANDIDATES = [
    "NAICS_2022_6_NAME","NAICS_2022_5_NAME","NAICS_2022_4_NAME","NAICS_2022_3_NAME","NAICS_2022_2_NAME",
    "NAICS6_NAME","NAICS5_NAME","NAICS4_NAME","NAICS3_NAME","NAICS2_NAME",
    "LIGHTCAST_SECTORS_NAME","INDUSTRY","INDUSTRY_NAME"
]
SALARY_CANDIDATES = ["SALARY","SALARY_MEDIAN","SALARY_MID","SALARY_ANNUAL","PAY_RATE"]

industry_col = next((c for c in INDUSTRY_CANDIDATES if c in df.columns), None)
salary_col   = next((c for c in SALARY_CANDIDATES if c in df.columns), None)

print("Chosen industry column:", industry_col)
print("Chosen salary column:", salary_col)
```

## Job Postings by Industry
```{python}
import plotly.express as px

if industry_col is None:
    print("No industry-like column available for chart.")
else:
    counts = (
        df[industry_col]
        .value_counts(dropna=False)
        .head(15)
        .reset_index(name="Job Postings")
        .rename(columns={"index": "Industry"})
        .sort_values("Job Postings")
    )
    fig = px.bar(
        counts, x="Job Postings", y="Industry", orientation="h",
        title="Top 15 Industries by Number of Job Postings"
    )
    fig.show()
```

## Salary Distribution by Industry
```{python}
import numpy as np, plotly.express as px

if (industry_col is None) or (salary_col is None):
    print("Missing salary or industry column for plot.")
else:
    sdf = df[[industry_col, salary_col]].copy()
    sdf.loc[:, salary_col] = pd.to_numeric(sdf[salary_col], errors="coerce")
    sdf = sdf.dropna(subset=[salary_col])
    sdf = sdf[sdf[salary_col] > 0]

    if sdf.empty:
        print("No salary data available for boxplot after cleaning.")
    else:
        fig2 = px.box(
            sdf, x=industry_col, y=salary_col,
            title="Salary Distribution by Industry", points=False
        )
        fig2.update_layout(xaxis_tickangle=-45)
        fig2.show()
```

## Remote vs. On-Site Jobs
```{python}
import plotly.express as px

col = "REMOTE_TYPE_NAME" if "REMOTE_TYPE_NAME" in df.columns else None
if col is None:
    print("No REMOTE_TYPE_NAME column available.")
else:
    rc = df[col].fillna("Unknown").value_counts().reset_index()
    rc.columns = ["Remote Type","Count"]
    fig3 = px.pie(rc, names="Remote Type", values="Count",
                  title="Remote vs. On-Site Job Distribution")
    fig3.show()
```

## EDA: Rationale & Insights

### Why these visualizations
- **Job Postings by Industry (bar chart)** compares demand across industries to prioritize where to focus a job search.
- **Salary Distribution by Industry (box plot)** shows median and spread, robust to skew in salary data.
- **Remote vs. On-Site (pie chart)** summarizes work-arrangement mix to set expectations for location flexibility.

### Key insights from the graphs
- **Industry demand:** A few industries dominate postings; target those first while keeping secondary sectors.
- **Salary patterns:** Wide dispersion in some industries implies upside for well-positioned candidates.
- **Work arrangement mix:** Higher remote share expands options; lower share requires local strategy.
- **Actionable takeaway:** Combine where **demand** is high, where **salary upside** exists, and where **work arrangement** fits your constraints to prioritize applications.
