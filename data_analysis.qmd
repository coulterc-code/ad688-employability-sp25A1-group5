---
title: "Data Analysis"
subtitle: "Comprehensive Data Cleaning & Exploratory Data Analysis of Job Market Trends"
author:
  - name: Connor Coulter
    affiliations:
      - id: bu
        name: Boston University
        city: Boston
        state: MA
  - name: Wei Wang
    affiliations:
      - ref: bu
  - name: Balqis Bevi Abdul Hannan Kanaga
    affiliations:
      - ref: bu
bibliography: references.bib
csl: csl/econometrica.csl
format: 
  html:
    embed-resources: true
    toc: true
    number-sections: true
    df-print: paged
execute:
  echo: false
  eval: true
  freeze: false
jupyter: python3
---

# Import Data

```{python}
import pandas as pd
import numpy as np

CSV_PATH = "data/lightcast_job_postings.csv"
df = pd.read_csv(CSV_PATH, low_memory=False)

print("Loaded dataset:", df.shape)
display(df.head(5))
```

# Data Cleaning & Preprocessing

## Create Robust Derived Columns (before any dropping)
```{python}
# 1) INDUSTRY_DISPLAY: pick the first available industry/NAICS name column
INDUSTRY_CANDIDATES = [
    "NAICS_2022_6_NAME","NAICS_2022_5_NAME","NAICS_2022_4_NAME","NAICS_2022_3_NAME","NAICS_2022_2_NAME",
    "NAICS6_NAME","NAICS5_NAME","NAICS4_NAME","NAICS3_NAME","NAICS2_NAME",
    "LIGHTCAST_SECTORS_NAME","SECTOR_NAME","INDUSTRY","INDUSTRY_NAME"
]
existing_industry = [c for c in INDUSTRY_CANDIDATES if c in df.columns]
if existing_industry:
    df["INDUSTRY_DISPLAY"] = df[existing_industry].bfill(axis=1).iloc[:, 0]
else:
    df["INDUSTRY_DISPLAY"] = np.nan  # will show message later if all missing

# 2) SALARY_DISPLAY (numeric, annualized where possible)
# Priority A: SALARY
salary_series = None
if "SALARY" in df.columns:
    salary_series = pd.to_numeric(df["SALARY"], errors="coerce")

# Priority B: midpoint of SALARY_FROM / SALARY_TO
if salary_series is None or salary_series.isna().all():
    if {"SALARY_FROM","SALARY_TO"}.issubset(df.columns):
        lo = pd.to_numeric(df["SALARY_FROM"], errors="coerce")
        hi = pd.to_numeric(df["SALARY_TO"], errors="coerce")
        mid = (lo + hi) / 2
        if not mid.isna().all():
            salary_series = mid

# Priority C: annualize PAY_RATE using ORIGINAL_PAY_PERIOD (HOUR/WEEK/MONTH/YEAR)
if (salary_series is None or salary_series.isna().all()) and "PAY_RATE" in df.columns:
    pay = pd.to_numeric(df["PAY_RATE"], errors="coerce")
    period = df["ORIGINAL_PAY_PERIOD"].astype(str).str.upper() if "ORIGINAL_PAY_PERIOD" in df.columns else "YEAR"
    factor = np.where(period.str.contains("HOUR"), 2080,
             np.where(period.str.contains("WEEK"), 52,
             np.where(period.str.contains("MONTH"), 12, 1)))
    annual = pay * factor
    if not annual.isna().all():
        salary_series = annual

# Assign SALARY_DISPLAY if we found something
if salary_series is not None:
    df["SALARY_DISPLAY"] = pd.to_numeric(salary_series, errors="coerce")
else:
    df["SALARY_DISPLAY"] = np.nan

print("Derived columns created. Non-null counts:",
      {"INDUSTRY_DISPLAY": int(df["INDUSTRY_DISPLAY"].notna().sum()),
       "SALARY_DISPLAY": int(df["SALARY_DISPLAY"].notna().sum())})
```

## Drop Unnecessary Columns
```{python}
columns_to_drop = [
    "ID","LAST_UPDATED_TIMESTAMP","DUPLICATES","ACTIVE_URLS","ACTIVE_SOURCES_INFO","URL","SOURCES","SOURCE_TYPES",
    "TITLE_RAW","BODY","COMPANY_RAW",
    "NAICS2","NAICS2_NAME","NAICS3","NAICS3_NAME","NAICS4","NAICS4_NAME","NAICS5","NAICS5_NAME","NAICS6","NAICS6_NAME",
    "NAICS_2022_2","NAICS_2022_2_NAME","NAICS_2022_3","NAICS_2022_3_NAME","NAICS_2022_4","NAICS_2022_4_NAME","NAICS_2022_5","NAICS_2022_5_NAME",
    "SOC_2","SOC_2_NAME","SOC_3","SOC_3_NAME","SOC_5","SOC_5_NAME",
    "CIP2","CIP2_NAME","CIP4","CIP4_NAME","CIP6","CIP6_NAME",
    "LOT_CAREER_AREA","LOT_CAREER_AREA_NAME","LOT_OCCUPATION","LOT_OCCUPATION_NAME",
    "LOT_SPECIALIZED_OCCUPATION","LOT_SPECIALIZED_OCCUPATION_NAME",
    "LOT_OCCUPATION_GROUP","LOT_OCCUPATION_GROUP_NAME",
    "LOT_V6_SPECIALIZED_OCCUPATION","LOT_V6_SPECIALIZED_OCCUPATION_NAME",
    "LOT_V6_OCCUPATION","LOT_V6_OCCUPATION_NAME","LOT_V6_OCCUPATION_GROUP","LOT_V6_OCCUPATION_GROUP_NAME",
    "LOT_V6_CAREER_AREA","LOT_V6_CAREER_AREA_NAME","ONET","ONET_NAME","ONET_2019","ONET_2019_NAME"
]
existing = [c for c in columns_to_drop if c in df.columns]
df = df.drop(columns=existing, errors="ignore")
print("Remaining columns (first 30):", list(df.columns)[:30])
```

## Handle Missing Values
```{python}
# Optional missingness heatmap
try:
    import missingno as msno, matplotlib.pyplot as plt
    msno.heatmap(df)
    plt.title("Missing Values Heatmap")
    plt.show()
except Exception as e:
    print("missingno heatmap skipped:", e)

# Don't drop our derived columns; temporarily set a high threshold but exclude derived fields
cols_to_consider = [c for c in df.columns if c not in ["INDUSTRY_DISPLAY","SALARY_DISPLAY"]]
df_non_derived = df[cols_to_consider]
keep = df_non_derived.dropna(thresh=len(df) * 0.5, axis=1)
df = pd.concat([keep, df[["INDUSTRY_DISPLAY","SALARY_DISPLAY"]]], axis=1)

# Numeric cleanup on SALARY_DISPLAY
df["SALARY_DISPLAY"] = pd.to_numeric(df["SALARY_DISPLAY"], errors="coerce")
med = df["SALARY_DISPLAY"].median() if df["SALARY_DISPLAY"].notna().any() else np.nan
if not np.isnan(med):
    df["SALARY_DISPLAY"] = df["SALARY_DISPLAY"].fillna(med)

# Fill categorical NAs without chained assignment
for col in df.select_dtypes(include="object").columns:
    df.loc[:, col] = df[col].fillna("Unknown")
```

## Remove Duplicates
```{python}
subset_cols = [c for c in ["TITLE","COMPANY_NAME","LOCATION","POSTED"] if c in df.columns]
if subset_cols:
    before = len(df)
    df = df.drop_duplicates(subset=subset_cols, keep="first")
    print(f"Removed {before - len(df)} duplicates using {subset_cols}")
else:
    print("No standard duplicate keys found; skipping.")
```

# Exploratory Data Analysis (EDA)

```{python}
print("Final non-null counts:",
      {"INDUSTRY_DISPLAY": int(df["INDUSTRY_DISPLAY"].notna().sum()),
       "SALARY_DISPLAY": int(df["SALARY_DISPLAY"].notna().sum())})
```

## Job Postings by Industry
```{python}
import plotly.express as px

if df["INDUSTRY_DISPLAY"].notna().sum() == 0:
    print("No industry values available for chart.")
else:
    counts = (
        df["INDUSTRY_DISPLAY"]
        .value_counts(dropna=False)
        .head(15)
        .reset_index(name="Job Postings")
        .rename(columns={"index": "Industry"})
        .sort_values("Job Postings")
    )
    fig = px.bar(
        counts, x="Job Postings", y="Industry", orientation="h",
        title="Top 15 Industries by Number of Job Postings"
    )
    fig.show()
```

## Salary Distribution by Industry
```{python}
import plotly.express as px

valid = df.dropna(subset=["INDUSTRY_DISPLAY","SALARY_DISPLAY"])
valid = valid[valid["SALARY_DISPLAY"] > 0]

if valid.empty:
    print("No salary data available for boxplot after cleaning.")
else:
    fig2 = px.box(
        valid, x="INDUSTRY_DISPLAY", y="SALARY_DISPLAY",
        title="Salary Distribution by Industry", points=False
    )
    fig2.update_layout(xaxis_tickangle=-45)
    fig2.show()
```

## Remote vs. On-Site Jobs
```{python}
import plotly.express as px

col = "REMOTE_TYPE_NAME" if "REMOTE_TYPE_NAME" in df.columns else None
if col is None:
    print("No REMOTE_TYPE_NAME column available.")
else:
    rc = df[col].fillna("Unknown").value_counts().reset_index()
    rc.columns = ["Remote Type","Count"]
    fig3 = px.pie(rc, names="Remote Type", values="Count",
                  title="Remote vs. On-Site Job Distribution")
    fig3.show()
```

## EDA: Rationale & Insights

### Why these visualizations
- **Job Postings by Industry** compares demand across industries to prioritize where to focus a job search.
- **Salary Distribution by Industry** shows central tendency and spread, robust to skew/outliers.
- **Remote vs. On-Site** summarizes work-arrangement mix to set expectations for location flexibility.

### Key insights from the graphs
- **Industry demand:** A few industries typically dominate postings; target those first while keeping secondary sectors in play.
- **Salary patterns:** Wide dispersion implies upside for well-positioned candidates and the need to negotiate.
- **Work arrangement mix:** Higher remote share expands geographic options; lower share reinforces local strategy.
