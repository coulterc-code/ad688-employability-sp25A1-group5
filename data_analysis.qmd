---
title: "Data Analysis"
subtitle: "Comprehensive Data Cleaning & Exploratory Analysis of Job Market Trends"
author:
  - name: Connor Coulter
    affiliations:
      - id: bu
        name: Boston University
        city: Boston
        state: MA
  - name: Wei Wang
    affiliations:
      - ref: bu
  - name: Balqis Bevi Abdul Hannan Kanaga
    affiliations:
      - ref: bu
bibliography: references.bib
csl: csl/econometrica.csl
format: 
  html:
    embed-resources: true
    toc: true
    number-sections: true
    df-print: paged
execute:
  echo: true
  eval: true
  freeze: auto
jupyter: python3
---

# Import Data

We load the job postings dataset using pandas and preview the first few rows.

```{python}
import pandas as pd

df = pd.read_csv("lightcast_job_postings.csv", low_memory=False)

print("Rows, Cols:", df.shape)
print(df.dtypes.head(20))
df.head(5)
```

# Data Cleaning & Preprocessing

## Dropping Unnecessary Columns
The dataset includes redundant or irrelevant fields. We remove tracking IDs, outdated codes, unstructured text, and alternate classification systems.

```{python}
columns_to_drop = [
    "ID", "LAST_UPDATED_TIMESTAMP", "DUPLICATES", "ACTIVE_URLS", "ACTIVE_SOURCES_INFO",
    "TITLE_RAW", "BODY", "COMPANY_RAW",
    "NAICS2", "NAICS2_NAME", "NAICS3", "NAICS3_NAME", "NAICS4", "NAICS4_NAME",
    "NAICS5", "NAICS5_NAME", "NAICS6", "NAICS6_NAME",
    "NAICS_2022_2", "NAICS_2022_2_NAME", "NAICS_2022_3", "NAICS_2022_3_NAME",
    "NAICS_2022_4", "NAICS_2022_4_NAME", "NAICS_2022_5", "NAICS_2022_5_NAME",
    "SOC_2", "SOC_2_NAME", "SOC_3", "SOC_3_NAME", "SOC_5", "SOC_5_NAME",
    "CIP2", "CIP2_NAME", "CIP4", "CIP4_NAME", "CIP6", "CIP6_NAME",
    "LOT_CAREER_AREA", "LOT_CAREER_AREA_NAME", "LOT_OCCUPATION", "LOT_OCCUPATION_NAME",
    "LOT_SPECIALIZED_OCCUPATION", "LOT_SPECIALIZED_OCCUPATION_NAME",
    "LOT_OCCUPATION_GROUP", "LOT_OCCUPATION_GROUP_NAME",
    "LOT_V6_SPECIALIZED_OCCUPATION", "LOT_V6_SPECIALIZED_OCCUPATION_NAME",
    "LOT_V6_OCCUPATION", "LOT_V6_OCCUPATION_NAME", "LOT_V6_OCCUPATION_GROUP",
    "LOT_V6_OCCUPATION_GROUP_NAME", "LOT_V6_CAREER_AREA", "LOT_V6_CAREER_AREA_NAME",
    "ONET", "ONET_NAME", "ONET_2019", "ONET_2019_NAME"
]

existing_cols = [c for c in columns_to_drop if c in df.columns]
df.drop(columns=existing_cols, inplace=True)

print("Remaining columns:", df.columns.tolist())
```

## Handling Missing Values

```{python}
import missingno as msno
import matplotlib.pyplot as plt

# visualize missingness
msno.heatmap(df)
plt.title("Missing Values Heatmap")
plt.show()

# drop columns with >50% missing
df.dropna(thresh=len(df) * 0.5, axis=1, inplace=True)

# fill salary if present
if "SALARY" in df.columns:
    df["SALARY"].fillna(df["SALARY"].median(), inplace=True)

# fill categorical with "Unknown"
for col in df.select_dtypes(include="object").columns:
    df[col].fillna("Unknown", inplace=True)
```

## Removing Duplicates

```{python}
df.drop_duplicates(
    subset=["TITLE", "COMPANY_NAME", "LOCATION", "POSTED"],
    keep="first",
    inplace=True
)
```

# Exploratory Data Analysis (EDA)

## Job Postings by Industry

```{python}
import plotly.express as px

industry_col = (
    "NAICS_2022_6_NAME" if "NAICS_2022_6_NAME" in df.columns
    else ("INDUSTRY" if "INDUSTRY" in df.columns else None)
)

if industry_col:
    industry_counts = (
        df[industry_col].value_counts().head(15).reset_index()
        .rename(columns={"index": "Industry", industry_col: "Job Postings"})
        .sort_values("Job Postings")
    )
    fig = px.bar(
        industry_counts,
        x="Job Postings",
        y="Industry",
        orientation="h",
        title="Top 15 Industries by Number of Job Postings"
    )
    fig.show()
else:
    print("No industry column available.")
```

## Salary Distribution by Industry

```{python}
import numpy as np

salary_candidates = ["SALARY", "SALARY_MEDIAN", "SALARY_MID", "SALARY_ANNUAL", "PAY_RATE"]
salary_col = next((c for c in salary_candidates if c in df.columns), None)

if salary_col and industry_col:
    sdf = df[[industry_col, salary_col]].copy()
    sdf[salary_col] = pd.to_numeric(sdf[salary_col], errors="coerce")
    sdf = sdf.dropna(subset=[salary_col]).query(f"{salary_col} > 0")

    fig2 = px.box(
        sdf,
        x=industry_col,
        y=salary_col,
        title="Salary Distribution by Industry",
        points=False
    )
    fig2.update_layout(xaxis_tickangle=-45)
    fig2.show()
else:
    print("Missing salary or industry column for plot.")
```

## Remote vs. On-Site Jobs

```{python}
if "REMOTE_TYPE_NAME" in df.columns:
    remote_counts = df["REMOTE_TYPE_NAME"].value_counts().reset_index()
    remote_counts.columns = ["Remote Type", "Count"]
    fig3 = px.pie(
        remote_counts,
        names="Remote Type",
        values="Count",
        title="Remote vs. On-Site Job Distribution"
    )
    fig3.show()
else:
    print("No remote type column available.")
```

## Exploratory Data Analysis (EDA): Rationale & Insights

### Why these visualizations
- **Job Postings by Industry (bar chart)** compares demand across industries to prioritize where to focus a job search.
- **Salary Distribution by Industry (box plot)** shows median and spread, robust to skew in salary data.
- **Remote vs. On-Site (pie chart)** summarizes work-arrangement mix to set expectations for location flexibility.

### Key insights from the graphs
- **Industry demand:** A few industries dominate postings; target those first while keeping secondary sectors.
- **Salary patterns:** Wide dispersion in some industries implies upside for well-positioned candidates.
- **Work arrangement mix:** Higher remote share expands options; lower share requires local strategy.
- **Actionable takeaway:** Combine where **demand** is high, where **salary upside** exists, and where **work arrangement** fits your constraints to prioritize applications.
